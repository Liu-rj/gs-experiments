{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/dgl/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import time\n",
    "import numpy as np\n",
    "import gs\n",
    "from gs.utils import SeedGenerator\n",
    "import numba\n",
    "from numba.core import types\n",
    "from numba.typed import Dict\n",
    "from dgl.utils import gather_pinned_tensor_rows\n",
    "from ogb.nodeproppred import DglNodePropPredDataset\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "\n",
    "def load_ogb(name):\n",
    "    data = DglNodePropPredDataset(name=name, root=\"../datasets\")\n",
    "    splitted_idx = data.get_idx_split()\n",
    "    g, labels = data[0]\n",
    "    g = g.long()\n",
    "    feat = g.ndata['feat']\n",
    "    labels = labels[:, 0]\n",
    "    n_classes = len(torch.unique(\n",
    "        labels[torch.logical_not(torch.isnan(labels))]))\n",
    "    g.ndata.clear()\n",
    "    g = dgl.remove_self_loop(g)\n",
    "    g = dgl.add_self_loop(g)\n",
    "    return g, feat, labels, n_classes, splitted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_ogb('ogbn-products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgl_graph = dataset[0]\n",
    "g = dgl_graph.long()\n",
    "probs = g.out_degrees().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.778319835662842 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created': ['coo', 'csr'], 'not created': ['csc']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.formats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = g.nodes().cuda()\n",
    "probs_cuda = probs.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8056907653808594 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_nodes = nodes[:2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8056907653808594 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.722006320953369 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "subg = dgl.in_subgraph(g, seed_nodes)\n",
    "print(torch.cuda.max_memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created': ['coo', 'csr', 'csc'], 'not created': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.formats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created': ['coo'], 'not created': ['csr', 'csc']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subg.formats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.711845397949219 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = subg.edges()\n",
    "nodes = torch.unique(edges[0])  # coo row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2423677444458008 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2423982620239258 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "num_pick = np.min([nodes.shape[0], 2000])\n",
    "node_probs = probs[nodes]\n",
    "idx = torch.multinomial(node_probs, num_pick, replacement=False)  # gpu\n",
    "selected = nodes[idx]  # gpu\n",
    "print(torch.cuda.max_memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2423830032348633 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2423830032348633 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "out_subg = dgl.out_subgraph(subg, selected)\n",
    "print(torch.cuda.max_memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24150"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subg.edges()[0].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_subg.edges()[0].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2423830032348633 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created': ['coo', 'csr'], 'not created': ['csc']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subg.formats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111059956"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subg.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created': ['coo', 'csr', 'csc'], 'not created': []}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.formats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0705080032348633 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "temp = torch.ones(111059956, dtype=torch.long, device='cuda')\n",
    "print(torch.cuda.max_memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0705080032348633 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0705080032348633 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "csr_subg = subg.formats('csr')\n",
    "print(torch.cuda.max_memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.multidigraph.MultiDiGraph at 0x7f9e6450dee0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_subg.metagraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiAdjacencyView({'_N': {'_N': {'_E': {}}}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_subg.metagraph().adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111059956"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_subg.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0705080032348633 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0705080032348633 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "subg.create_formats_()\n",
    "print(torch.cuda.max_memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created': ['coo', 'csr', 'csc'], 'not created': []}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subg.formats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_subg.idtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0705080032348633 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=111059956, num_edges=24150,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_subg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0705080032348633 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0705080032348633 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "csr_subg.metagraph()\n",
    "print(torch.cuda.max_memory_allocated() / (1024 * 1024 * 1024), 'GB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dgl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "680fc764c247143fec7ade4e9e187021f4298c94812dc3ced2ffcb33d31f8158"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
